{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#estrazione dataset\n",
    "nomi_folder = os.listdir(\"dataset_MMSI\")\n",
    "df_dataset= pd.DataFrame()\n",
    "for nome_file in nomi_folder:\n",
    "    df = pd.read_csv(os.path.join(\"dataset_MMSI\", nome_file));\n",
    "    df_dataset = pd.concat([df_dataset, df]);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset_original=df_dataset.copy() #nuovo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_dataset_for_cluster=df_dataset_original.copy()\n",
    "df_dataset_for_cluster.drop(['MMSI','BaseDateTime','Time','LAT','LON','DistMtr','Status','Heading','COG'], axis=1, inplace=True)\n",
    "df_dataset_for_cluster.reset_index(drop=True)\n",
    "scaler.fit(df_dataset_for_cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Riduzione della dimensionalità utilizzando PCA\n",
    "pca = PCA(n_components=0.99)  # Manteniamo il 95% della varianza\n",
    "df_dataset_for_cluster = pca.fit_transform(df_dataset_for_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "# Addestramento del modello GMM\n",
    "n_components = 5  # Definiamo il numero di componenti (cluster)\n",
    "gmm = GaussianMixture(n_components=n_components)\n",
    "gmm.fit(df_dataset_for_cluster)\n",
    "# Predizione dei cluster\n",
    "clusters = gmm.predict(df_dataset_for_cluster)\n",
    "del df_dataset_for_cluster\n",
    "df_dataset_original['state'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset = df_dataset_original[df_dataset_original['MMSI'] == 259790000]\n",
    "subset = df_dataset_original[df_dataset_original['MMSI'] == 636015465]\n",
    "#subset = df_dataset_original[df_dataset_original['MMSI'] == 636017317]\n",
    "#subset = df_dataset_original[df_dataset_original['MMSI'] == 367309860]\n",
    "#subset = df_dataset_original[df_dataset_original['MMSI'] == 367310240]# nave ferma al porto\n",
    "#subset = df_dataset_original[df_dataset_original['MMSI'] == 219253000]# nave ferma al porto\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from branca.element import Template, MacroElement\n",
    "\n",
    "# Crea un dizionario di colori per ciascuno stato\n",
    "color_dict = {0: 'blue', 1: 'green', 2: 'orange', 3: 'red',4:'violet',5:'cyan'}\n",
    "\n",
    "mapp = folium.Map([21, -158], zoom_start=6, tiles='cartodbpositron')\n",
    "\n",
    "for i in range(0, len(subset)):\n",
    "    state = subset.iloc[i]['state']\n",
    "    color = color_dict.get(state, 'black')  # Utilizza il colore corrispondente allo stato, o 'black' se lo stato non è nel dizionario\n",
    "    Head = subset.iloc[i]['Heading']  # Angolo COG\n",
    "    icon_angle = f\"\"\"transform: rotate({Head}deg);\"\"\"  # Applica la rotazione dell'icona in base all'angolo COG\n",
    "    folium.Marker(\n",
    "        location=[subset.iloc[i]['LAT'], subset.iloc[i]['LON']],\n",
    "        icon=folium.DivIcon(html=f\"\"\"<div style=\"font-size: 12pt; color: {color}; {icon_angle}\">➤</div>\"\"\"),\n",
    "        popup=str(state)\n",
    "    ).add_to(mapp)\n",
    "\n",
    "# Crea una heatmap\n",
    "mapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subset.drop(['MMSI','BaseDateTime','Time','LAT','LON','DistMtr','Status','Heading','COG'], axis=1, inplace=True)\n",
    "subset.reset_index(drop=True)\n",
    "# Aggregazione per gruppo e calcoli dei valori medi delle caratteristiche\n",
    "# considerando le osservazioni di ogni gruppo\n",
    "\n",
    "aggdata = subset.groupby('state').mean().reset_index()\n",
    "aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aggdata = subset.groupby('state').mean().reset_index()\n",
    "aggdata"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIS_anomaly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
